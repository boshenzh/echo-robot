#!/usr/bin/env python3
"""
Integrated Demo Script for Robot Arm with YOLO Detection and Audio
ÈõÜÊàêÊºîÁ§∫ËÑöÊú¨ÔºöÊú∫Âô®‰∫∫ÊâãËáÇ + YOLOÊ£ÄÊµã + Èü≥È¢ëÂèçÈ¶à

This script                # Quick calibration check
                calibrate = input("Calibrate robot? (y/n): ").strip().lower()
                if calibrate in ['y', 'yes']:
                    print("üîß Calibrating robot...")
                    self.robot.calibrate()
                    print("‚úÖ Calibration completed!")
                
                # Move to initial safe position
                print("üè† Moving to initial safe position...")
                self.move_to_safe_start_position()
                
            except Exception as e:
                print(f"‚ùå Robot connection failed: {e}")
                raise RuntimeError(f"‚ùå Failed to connect to robot at {port}. Check connection and port.")
        else:
            print("üéÆ Running in simulation mode")
    
    def move_to_safe_start_position(self):
        """ÁßªÂä®Âà∞ÂÆâÂÖ®ÁöÑËµ∑Âßã‰ΩçÁΩÆ"""
        try:
            # ËÆ°ÁÆóÂÆâÂÖ®Ëµ∑Âßã‰ΩçÁΩÆÁöÑÂÖ≥ËäÇËßíÂ∫¶
            safe_x, safe_y = 0.0, 0.16
            joint2, joint3 = self.inverse_kinematics(safe_x, safe_y)
            
            print(f"üîß Moving to safe start: x={safe_x}, y={safe_y}")
            print(f"   Joint angles: shoulder={joint2:.1f}¬∞, elbow={joint3:.1f}¬∞")
            
            robot_action = {
                'shoulder_lift.pos': joint2,
                'elbow_flex.pos': joint3
            }
            
            if not self.simulation_mode:
                self.robot.send_action(robot_action)
                time.sleep(2.0)  # Á≠âÂæÖÂà∞Ëææ‰ΩçÁΩÆ
            
            self.current_x = safe_x
            self.current_y = safe_y
            print("‚úÖ Robot moved to safe start position")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to move to safe start position: {e}")
            print("   Continuing with current position..."). Camera visualization with YOLO bottle detection (from test_camera_yolo.py)
2. Robot trajectory movement: forward/backward push (from lerobot_yolo.py)
3. Audio feedback before robot arm starts movement

Dependencies:
- pip install pygame (for audio)
ÊàñËÄÖ‰ΩøÁî®Á≥ªÁªüÈü≥È¢ëÔºö
- sudo apt-get install alsa-utils (for aplay)
"""

import cv2
import time
import math
import numpy as np
import threading
import logging
import traceback
import os
import sys
from ultralytics import YOLO

# Audio imports - try multiple options
try:
    import pygame
    AUDIO_METHOD = "pygame"
    print("üîä Using pygame for audio")
except ImportError:
    AUDIO_METHOD = "system"
    print("üîä Using system commands for audio")

# Robot imports (only if available)
try:
    from lerobot.robots.so100_follower import SO100Follower, SO100FollowerConfig
    ROBOT_AVAILABLE = True
    print("ü§ñ Robot modules available")
except ImportError:
    ROBOT_AVAILABLE = False
    print("‚ö†Ô∏è  Robot modules not available - simulation mode only")

# ËÆæÁΩÆÊó•Âøó
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AudioManager:
    """Èü≥È¢ëÁÆ°ÁêÜÂô®"""
    
    def __init__(self):
        self.audio_enabled = True
        if AUDIO_METHOD == "pygame":
            try:
                pygame.mixer.init()
                print("‚úÖ Pygame audio initialized")
            except Exception as e:
                print(f"‚ùå Pygame audio initialization failed: {e}")
                self.audio_enabled = False
    
    def play_alert_sound(self, sound_type="push"):
        """Êí≠ÊîæË≠¶ÂëäÈü≥"""
        if not self.audio_enabled:
            return
        
        try:
            if AUDIO_METHOD == "pygame":
                self._play_pygame_sound(sound_type)
            else:
                self._play_system_sound(sound_type)
        except Exception as e:
            print(f"‚ùå Audio playback failed: {e}")
    
    def _play_pygame_sound(self, sound_type):
        """‰ΩøÁî®pygameÊí≠ÊîæÂ£∞Èü≥"""
        # ÁîüÊàêÁÆÄÂçïÁöÑËúÇÈ∏£Èü≥
        frequency = 800 if sound_type == "push" else 600
        duration = 0.5
        sample_rate = 22050
        
        # ÁîüÊàêÊ≠£Âº¶Ê≥¢
        frames = int(duration * sample_rate)
        arr = np.zeros((frames, 2))
        
        for i in range(frames):
            wave = np.sin(2 * np.pi * frequency * i / sample_rate)
            arr[i] = [wave, wave]
        
        # ËΩ¨Êç¢‰∏∫pygameÊ†ºÂºèÂπ∂Êí≠Êîæ
        sound_array = (arr * 32767).astype(np.int16)
        sound = pygame.sndarray.make_sound(sound_array)
        sound.play()
        time.sleep(duration)
    
    def _play_system_sound(self, sound_type):
        """‰ΩøÁî®Á≥ªÁªüÂëΩ‰ª§Êí≠ÊîæÂ£∞Èü≥"""
        if sound_type == "push":
            # È´òÈü≥Ë∞ÉË≠¶Âëä
            os.system("speaker-test -t sine -f 800 -l 1 > /dev/null 2>&1 &")
        else:
            # ‰ΩéÈü≥Ë∞ÉÊèêÁ§∫
            os.system("speaker-test -t sine -f 600 -l 1 > /dev/null 2>&1 &")
        time.sleep(0.1)
    
    def cleanup(self):
        """Ê∏ÖÁêÜÈü≥È¢ëËµÑÊ∫ê"""
        if AUDIO_METHOD == "pygame":
            try:
                pygame.mixer.quit()
            except:
                pass

class RobotController:
    """Êú∫Âô®‰∫∫ÊéßÂà∂Âô®"""
    
    def __init__(self, port="/dev/ttyACM1", simulation_mode=False):
        self.simulation_mode = simulation_mode or not ROBOT_AVAILABLE
        self.robot = None
        self.current_x = 0.0
        self.current_y = 0.06  # ÂàùÂßãy‰ΩçÁΩÆ - Âú®Êú∫Âô®‰∫∫Â∑•‰ΩúÁ©∫Èó¥ÂÜÖ
        self.is_moving = False
        
        if not ROBOT_AVAILABLE:
            raise RuntimeError("‚ùå Robot modules not available! Please install lerobot package.")
        
        if not self.simulation_mode:
            try:
                print(f"üîå Connecting to robot at {port}...")
                robot_config = SO100FollowerConfig(port=port)
                self.robot = SO100Follower(robot_config)
                self.robot.connect()
                print("‚úÖ Robot connected successfully!")
                
                # Quick calibration check
                calibrate = input("Calibrate robot? (y/n): ").strip().lower()
                if calibrate in ['y', 'yes']:
                    print("ÔøΩ Calibrating robot...")
                    self.robot.calibrate()
                    print("‚úÖ Calibration completed!")
                
            except Exception as e:
                print(f"‚ùå Robot connection failed: {e}")
                raise RuntimeError(f"‚ùå Failed to connect to robot at {port}. Check connection and port.")
        else:
            print("üéÆ Running in simulation mode")
    
    def inverse_kinematics(self, x, y, l1=0.1159, l2=0.1350):
        """
        Calculate inverse kinematics for a 2-link robotic arm
        ‰ªélerobot_yolo.pyÂ§çÂà∂ÁöÑÈÄÜËøêÂä®Â≠¶ËÆ°ÁÆó
        """
        # Calculate joint2 and joint3 offsets in theta1 and theta2
        theta1_offset = math.atan2(0.028, 0.11257)  # theta1 offset when joint2=0
        theta2_offset = math.atan2(0.0052, 0.1349) + theta1_offset  # theta2 offset when joint3=0
        
        # Calculate distance from origin to target point
        r = math.sqrt(x**2 + y**2)
        r_max = l1 + l2  # Maximum reachable distance
        
        # If target point is beyond maximum workspace, scale it to the boundary
        if r > r_max:
            scale_factor = r_max / r
            x *= scale_factor
            y *= scale_factor
            r = r_max
        
        # If target point is less than minimum workspace (|l1-l2|), scale it
        r_min = abs(l1 - l2)
        if r < r_min and r > 0:
            scale_factor = r_min / r
            x *= scale_factor
            y *= scale_factor
            r = r_min
        
        # Use law of cosines to calculate theta2
        cos_theta2 = -(r**2 - l1**2 - l2**2) / (2 * l1 * l2)
        
        # Calculate theta2 (elbow angle)
        theta2 = math.pi - math.acos(cos_theta2)
        
        # Calculate theta1 (shoulder angle)
        beta = math.atan2(y, x)
        gamma = math.atan2(l2 * math.sin(theta2), l1 + l2 * math.cos(theta2))
        theta1 = beta + gamma
        
        # Convert theta1 and theta2 to joint2 and joint3 angles
        joint2 = theta1 + theta1_offset
        joint3 = theta2 + theta2_offset
        
        # Ensure angles are within URDF limits
        joint2 = max(-0.1, min(3.45, joint2))
        joint3 = max(-0.2, min(math.pi, joint3))
        
        # Convert from radians to degrees
        joint2_deg = math.degrees(joint2)
        joint3_deg = math.degrees(joint3)
        
        joint2_deg = 90 - joint2_deg
        joint3_deg = joint3_deg - 90
        
        return joint2_deg, joint3_deg
    
    def move_to_position(self, target_x, target_y, duration=4.0, num_waypoints=5):
        """ÁßªÂä®Âà∞ÊåáÂÆö‰ΩçÁΩÆ - ‰ΩøÁî®Â§ö‰∏™Ëà™ÁÇπÂÆûÁé∞Âπ≥ÊªëËøêÂä®"""
        self.is_moving = True
        print(f"üéØ Moving to position: x={target_x:.3f}, y={target_y:.3f} (duration: {duration}s)")
        
        # È™åËØÅÁõÆÊ†á‰ΩçÁΩÆÊòØÂê¶Âú®Â∑•‰ΩúÁ©∫Èó¥ÂÜÖ
        distance_from_origin = math.sqrt(target_x**2 + target_y**2)
        l1, l2 = 0.1159, 0.1350
        max_reach = l1 + l2
        min_reach = abs(l1 - l2)
        
        if distance_from_origin > max_reach:
            print(f"‚ö†Ô∏è  Target position ({target_x:.3f}, {target_y:.3f}) is beyond max reach {max_reach:.3f}m")
            print(f"   Scaling to workspace boundary...")
            scale = max_reach / distance_from_origin
            target_x *= scale
            target_y *= scale
            print(f"   New target: ({target_x:.3f}, {target_y:.3f})")
        elif distance_from_origin < min_reach and distance_from_origin > 0:
            print(f"‚ö†Ô∏è  Target position ({target_x:.3f}, {target_y:.3f}) is within min reach {min_reach:.3f}m")
            print(f"   Scaling to minimum workspace...")
            scale = min_reach / distance_from_origin
            target_x *= scale
            target_y *= scale
            print(f"   New target: ({target_x:.3f}, {target_y:.3f})")
        
        start_x, start_y = self.current_x, self.current_y
        
        # ÁîüÊàê‰∏≠Èó¥Ëà™ÁÇπ
        waypoints = []
        for i in range(num_waypoints + 1):
            progress = i / num_waypoints
            # ‰ΩøÁî®Âπ≥ÊªëÁöÑSÊõ≤Á∫øÊèíÂÄºÔºàÁºìËøõÁºìÂá∫Ôºâ
            smooth_progress = self._smooth_interpolation(progress)
            
            wp_x = start_x + (target_x - start_x) * smooth_progress
            wp_y = start_y + (target_y - start_y) * smooth_progress
            waypoints.append((wp_x, wp_y))
        
        print(f"üìç Generated {len(waypoints)} waypoints for smooth trajectory")
        
        if self.simulation_mode:
            # Ê®°ÊãüÁßªÂä® - ÈÄöËøáÊØè‰∏™Ëà™ÁÇπ
            waypoint_duration = duration / num_waypoints
            
            for i, (wp_x, wp_y) in enumerate(waypoints[1:], 1):  # Ë∑≥ËøáËµ∑ÂßãÁÇπ
                print(f"üéØ Waypoint {i}/{num_waypoints}: x={wp_x:.3f}, y={wp_y:.3f}")
                
                # ÊØè‰∏™Ëà™ÁÇπÂÜÖÈÉ®ÁöÑÁªÜÂàÜÊ≠•È™§
                steps_per_waypoint = int(waypoint_duration * 20)  # 20Hz for smooth simulation
                prev_x, prev_y = self.current_x, self.current_y
                
                for j in range(steps_per_waypoint + 1):
                    step_progress = j / steps_per_waypoint
                    
                    current_x = prev_x + (wp_x - prev_x) * step_progress
                    current_y = prev_y + (wp_y - prev_y) * step_progress
                    
                    self.current_x = current_x
                    self.current_y = current_y
                    
                    if j % 10 == 0:  # ÊØè0.5ÁßíÊòæÁ§∫‰∏ÄÊ¨°‰ΩçÁΩÆ
                        print(f"   üìç Position: x={current_x:.3f}, y={current_y:.3f}")
                    
                    time.sleep(waypoint_duration / steps_per_waypoint)
        else:
            # ÁúüÂÆûÊú∫Âô®‰∫∫ÁßªÂä® - ÈÄöËøáÊØè‰∏™Ëà™ÁÇπ
            try:
                control_freq = 30  # 30HzÊéßÂà∂È¢ëÁéá
                waypoint_duration = duration / num_waypoints
                steps_per_waypoint = int(waypoint_duration * control_freq)
                
                for i, (wp_x, wp_y) in enumerate(waypoints[1:], 1):  # Ë∑≥ËøáËµ∑ÂßãÁÇπ
                    print(f"üéØ Waypoint {i}/{num_waypoints}: x={wp_x:.3f}, y={wp_y:.3f}")
                    
                    # ËÆ°ÁÆóËØ•Ëà™ÁÇπÁöÑÂÖ≥ËäÇËßíÂ∫¶
                    joint2, joint3 = self.inverse_kinematics(wp_x, wp_y)
                    print(f"   üîß Joint angles: shoulder={joint2:.1f}¬∞, elbow={joint3:.1f}¬∞")
                    
                    # ‰ªéÂΩìÂâç‰ΩçÁΩÆÂπ≥ÊªëÁßªÂä®Âà∞Ëà™ÁÇπ
                    prev_x, prev_y = self.current_x, self.current_y
                    
                    for j in range(steps_per_waypoint):
                        step_progress = j / steps_per_waypoint
                        
                        # ÂΩìÂâçÊ≠•È™§ÁöÑÁõÆÊ†á‰ΩçÁΩÆ
                        intermediate_x = prev_x + (wp_x - prev_x) * step_progress
                        intermediate_y = prev_y + (wp_y - prev_y) * step_progress
                        
                        # ËÆ°ÁÆó‰∏≠Èó¥‰ΩçÁΩÆÁöÑÂÖ≥ËäÇËßíÂ∫¶
                        inter_joint2, inter_joint3 = self.inverse_kinematics(intermediate_x, intermediate_y)
                        
                        robot_action = {
                            'shoulder_lift.pos': inter_joint2,
                            'elbow_flex.pos': inter_joint3
                        }
                        
                        self.robot.send_action(robot_action)
                        time.sleep(1.0 / control_freq)
                    
                    # Êõ¥Êñ∞ÂΩìÂâç‰ΩçÁΩÆÂà∞Ëà™ÁÇπ‰ΩçÁΩÆ
                    self.current_x = wp_x
                    self.current_y = wp_y
                    
                    if i % 2 == 0:  # ÊØèÈöî‰∏Ä‰∏™Ëà™ÁÇπÊòæÁ§∫‰ΩçÁΩÆ
                        print(f"   ‚úÖ Reached waypoint {i}: x={wp_x:.3f}, y={wp_y:.3f}")
                
                # ÊúÄÁªà‰ΩçÁΩÆÁ°ÆËÆ§
                self.current_x = target_x
                self.current_y = target_y
                
            except Exception as e:
                print(f"‚ùå Robot movement failed: {e}")
        
        self.is_moving = False
        print("‚úÖ Smooth movement completed")
    
    def _smooth_interpolation(self, t):
        """Âπ≥ÊªëÊèíÂÄºÂáΩÊï∞ - SÊõ≤Á∫øÔºàÁºìËøõÁºìÂá∫Ôºâ"""
        # ‰ΩøÁî®3Ê¨°Ë¥ùÂ°ûÂ∞îÊõ≤Á∫øÂÆûÁé∞Âπ≥ÊªëËøáÊ∏°
        # ËøôÊèê‰æõ‰∫ÜÁºìÊÖ¢ÂºÄÂßã„ÄÅÂä†ÈÄü„ÄÅÁÑ∂ÂêéÁºìÊÖ¢ÁªìÊùüÁöÑÊïàÊûú
        return t * t * (3.0 - 2.0 * t)
    
    def execute_push_trajectory(self, audio_manager):
        """ÊâßË°åÊé®Áì∂Âä®‰ΩúËΩ®Ëøπ - ÊÖ¢ÈÄüÂπ≥ÊªëËøêÂä®"""
        print("\n" + "="*60)
        print("üöÄ STARTING SMOOTH PUSH TRAJECTORY")
        print("="*60)
        
        # Êí≠ÊîæÈü≥È¢ëË≠¶Âëä
        print("üîä Playing audio alert...")
        audio_manager.play_alert_sound("push")
        
        # Á≠âÂæÖÈü≥È¢ëÊí≠ÊîæÂÆåÊàê
        time.sleep(1.0)
        
        # ÂÆö‰πâËΩ®ËøπÁÇπ
        start_pos = (0.0, 0.16)      # Ëµ∑Âßã‰ΩçÁΩÆ - Âú®Êú∫Âô®‰∫∫Â∑•‰ΩúÁ©∫Èó¥ÂÜÖ
        push_pos = (0.1, 0.16)       # Êé®Ëøõ‰ΩçÁΩÆ (10cm forward)
        
        print(f"\nüìã Smooth Trajectory Plan:")
        print(f"   üè† Start:  x={start_pos[0]:.3f}m, y={start_pos[1]:.3f}m")
        print(f"   üéØ Target: x={push_pos[0]:.3f}m, y={push_pos[1]:.3f}m")
        print(f"   ‚è±Ô∏è  Total time: ~12 seconds")
        print(f"   üõ§Ô∏è  Using 5 waypoints per movement")
        
        # Phase 1: ÂêëÂâçÊé®Ëøõ (ÊÖ¢ÈÄü)
        print(f"\n‚è© PHASE 1: Smooth Forward Push (5s)")
        self.move_to_position(push_pos[0], push_pos[1], duration=5.0, num_waypoints=5)
        
        # ËæÉÈïøÂÅúÁïôÊó∂Èó¥
        print(f"\n‚è∏Ô∏è  PHASE 2: Hold Position (2s)")
        print("   ü§ö Maintaining contact with bottle...")
        time.sleep(2.0)
        
        # Phase 3: ÂêëÂêéÈÄÄÂõû (ÊÖ¢ÈÄü)
        print(f"\n‚è™ PHASE 3: Smooth Backward Retreat (5s)")
        self.move_to_position(start_pos[0], start_pos[1], duration=5.0, num_waypoints=5)
        
        print(f"\n" + "="*60)
        print("‚úÖ SMOOTH PUSH TRAJECTORY COMPLETED!")
        print("   Total execution time: ~12 seconds")
        print("="*60)
    
    def disconnect(self):
        """Êñ≠ÂºÄÊú∫Âô®‰∫∫ËøûÊé•"""
        if self.robot and not self.simulation_mode:
            try:
                self.robot.disconnect()
                print("üîå Robot disconnected")
            except:
                pass

class CameraYOLOSystem:
    """ÊëÑÂÉèÂ§¥YOLOÊ£ÄÊµãÁ≥ªÁªü"""
    
    def __init__(self, camera_id=4, model_path="yolov8n.pt"):
        self.camera_id = camera_id
        self.model = None
        self.cap = None
        self.running = False
        self.detection_callback = None
        
        # ÂàùÂßãÂåñYOLOÊ®°Âûã
        try:
            self.model = YOLO(model_path)
            print("‚úÖ YOLO model loaded successfully")
        except Exception as e:
            print(f"‚ùå YOLO model loading failed: {e}")
    
    def auto_detect_camera(self):
        """Ëá™Âä®Ê£ÄÊµãÂèØÁî®ÊëÑÂÉèÂ§¥"""
        print("üîç Auto-detecting cameras...")
        available_cameras = []
        
        for camera_id in range(5):
            cap = cv2.VideoCapture(camera_id)
            if cap.isOpened():
                ret, _ = cap.read()
                if ret:
                    available_cameras.append(camera_id)
                    print(f"‚úÖ Camera {camera_id} detected")
                cap.release()
        
        if available_cameras:
            print(f"üì∑ Available cameras: {available_cameras}")
            return available_cameras[0]
        else:
            print("‚ùå No cameras detected")
            return None
    
    def initialize_camera(self):
        """ÂàùÂßãÂåñÊëÑÂÉèÂ§¥"""
        # Ëá™Âä®Ê£ÄÊµãÊàñ‰ΩøÁî®ÊåáÂÆöÊëÑÂÉèÂ§¥
        if self.camera_id is None:
            self.camera_id = self.auto_detect_camera()
            if self.camera_id is None:
                return False
        
        try:
            self.cap = cv2.VideoCapture(self.camera_id)
            if not self.cap.isOpened():
                print(f"‚ùå Cannot open camera {self.camera_id}")
                return False
            
            # ËÆæÁΩÆÊëÑÂÉèÂ§¥ÂèÇÊï∞
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            print(f"üì∑ Camera {self.camera_id} initialized successfully")
            return True
            
        except Exception as e:
            print(f"‚ùå Camera initialization failed: {e}")
            return False
    
    def set_detection_callback(self, callback):
        """ËÆæÁΩÆÊ£ÄÊµãÂõûË∞ÉÂáΩÊï∞"""
        self.detection_callback = callback
    
    def run_detection_loop(self, show_robot_status=False, robot_controller=None):
        """ËøêË°åÊ£ÄÊµãÂæ™ÁéØ"""
        if not self.model or not self.cap:
            print("‚ùå Camera or model not initialized")
            return
        
        self.running = True
        fps_counter = 0
        fps_display = 0
        prev_time = time.time()
        detection_count = 0
        start_time = time.time()
        
        print("üéØ Starting camera detection loop...")
        print("Controls:")
        print("  'q' or ESC: Quit")
        print("  's': Save current frame")
        print("  'p': Manual push trigger")
        if show_robot_status:
            print("  Robot runs automatically every 15 seconds")
        
        try:
            while self.running:
                ret, frame = self.cap.read()
                if not ret:
                    print("‚ùå Failed to capture frame")
                    break
                
                # YOLOÊ£ÄÊµã
                results = self.model(frame, device='cpu', verbose=False)
                
                # Â§ÑÁêÜÊ£ÄÊµãÁªìÊûú
                bottle_detected = False
                for result in results:
                    if result.boxes is not None:
                        for box in result.boxes:
                            x1, y1, x2, y2 = map(int, box.xyxy[0])
                            conf = float(box.conf[0])
                            cls = int(box.cls[0])
                            label = self.model.names[cls]
                            
                            # Âè™ÊòæÁ§∫ÁΩÆ‰ø°Â∫¶Â§ß‰∫é0.5ÁöÑÊ£ÄÊµãÁªìÊûú
                            if conf > 0.5:
                                detection_count += 1
                                
                                # Ê£ÄÊü•ÊòØÂê¶‰∏∫Áì∂Â≠ê
                                if 'bottle' in label.lower():
                                    bottle_detected = True
                                
                                # ËÆ°ÁÆó‰∏≠ÂøÉÁÇπ
                                center_x = (x1 + x2) // 2
                                center_y = (y1 + y2) // 2
                                
                                # ÁªòÂà∂Ê£ÄÊµãÊ°Ü
                                color = (0, 255, 255) if 'bottle' in label.lower() else (0, 255, 0)
                                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                                cv2.circle(frame, (center_x, center_y), 5, color, -1)
                                
                                # ÁªòÂà∂Ê†áÁ≠æ
                                label_text = f'{label} {conf:.2f}'
                                cv2.putText(frame, label_text, (x1, y1 - 10),
                                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                
                # ËÆ°ÁÆóFPS
                current_time = time.time()
                fps_counter += 1
                if current_time - prev_time >= 1.0:
                    fps_display = fps_counter
                    fps_counter = 0
                    prev_time = current_time
                
                # ÊòæÁ§∫‰ø°ÊÅØ
                info_y = 30
                cv2.putText(frame, f'FPS: {fps_display}', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                info_y += 30
                cv2.putText(frame, f'Camera: {self.camera_id}', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                info_y += 25
                cv2.putText(frame, f'Detections: {detection_count}', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # ÊòæÁ§∫ËøêË°åÊó∂Èó¥
                info_y += 25
                runtime = int(current_time - start_time)
                cv2.putText(frame, f'Runtime: {runtime}s', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # ÊòæÁ§∫Êú∫Âô®‰∫∫Áä∂ÊÄÅ
                if show_robot_status and robot_controller:
                    info_y += 25
                    robot_status = "MOVING" if robot_controller.is_moving else "READY"
                    status_color = (0, 165, 255) if robot_controller.is_moving else (0, 255, 0)
                    cv2.putText(frame, f'Robot: {robot_status}', (10, info_y),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 2)
                    
                    # ÊòæÁ§∫‰∏ãÊ¨°Ëá™Âä®Êé®ËøõÂÄíËÆ°Êó∂Ôºà‰º∞ÁÆóÔºâ
                    if not robot_controller.is_moving:
                        info_y += 25
                        # ÁÆÄÂçïÁöÑÂÄíËÆ°Êó∂‰º∞ÁÆó
                        time_since_start = runtime % 15  # ÂÅáËÆæ15ÁßíÂë®Êúü
                        next_push_in = 15 - time_since_start
                        cv2.putText(frame, f'Next auto push: {next_push_in}s', (10, info_y),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
                
                if bottle_detected:
                    info_y += 25
                    cv2.putText(frame, 'BOTTLE DETECTED!', (10, info_y),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                
                # ÊòæÁ§∫Ê®°Âºè‰ø°ÊÅØ
                if show_robot_status:
                    cv2.putText(frame, 'UNIFIED MODE: YOLO + TIMED ROBOT', (10, frame.shape[0] - 60),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 165, 0), 2)
                    cv2.putText(frame, 'Press P for manual push, Q to quit', (10, frame.shape[0] - 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                
                # ÊòæÁ§∫ÁîªÈù¢
                cv2.imshow('Robot Demo - YOLO Detection + Timed Robot', frame)
                
                # Ê£ÄÊü•ÊåâÈîÆ
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:  # ESCÈîÆÈÄÄÂá∫
                    break
                elif key == ord('s'):  # ‰øùÂ≠òÂΩìÂâçÂ∏ß
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    filename = f'demo_frame_{timestamp}.jpg'
                    cv2.imwrite(filename, frame)
                    print(f"üíæ Frame saved as {filename}")
                elif key == ord('p'):  # Ëß¶ÂèëÊé®Áì∂Âä®‰Ωú
                    if self.detection_callback:
                        print("üéØ Manual push trigger activated")
                        threading.Thread(target=self.detection_callback, daemon=True).start()
                
                # Ëá™Âä®Ëß¶ÂèëÔºàÂΩìÊ£ÄÊµãÂà∞Áì∂Â≠êÊó∂Ôºâ
                if bottle_detected and self.detection_callback:
                    # ÂèØ‰ª•Âú®ËøôÈáåÊ∑ªÂä†Ëá™Âä®Ëß¶ÂèëÈÄªËæë
                    pass
                    
        except KeyboardInterrupt:
            print("‚èπÔ∏è  Detection loop interrupted by user")
        finally:
            self.running = False
    
    def stop(self):
        """ÂÅúÊ≠¢Ê£ÄÊµã"""
        self.running = False
    
    def cleanup(self):
        """Ê∏ÖÁêÜËµÑÊ∫ê"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()

class IntegratedDemo:
    """ÈõÜÊàêÊºîÁ§∫Á≥ªÁªü"""
    
    def __init__(self):
        self.audio_manager = AudioManager()
        self.robot_controller = None
        self.camera_system = None
        self.demo_running = False
        
    def initialize_systems(self, robot_port="/dev/ttyACM1", camera_id=4, simulation_mode=False):
        """ÂàùÂßãÂåñÊâÄÊúâÁ≥ªÁªü"""
        print("üöÄ Initializing Integrated Demo System...")
        print("="*60)
        
        # ÂàùÂßãÂåñÊú∫Âô®‰∫∫ÊéßÂà∂Âô®
        print("ü§ñ Initializing robot controller...")
        self.robot_controller = RobotController(robot_port, simulation_mode)
        
        # ÂàùÂßãÂåñÊëÑÂÉèÂ§¥Á≥ªÁªü
        print("üì∑ Initializing camera system...")
        self.camera_system = CameraYOLOSystem(camera_id)
        
        if not self.camera_system.initialize_camera():
            print("‚ùå Camera system initialization failed")
            return False
        
        # ËÆæÁΩÆÊ£ÄÊµãÂõûË∞É
        self.camera_system.set_detection_callback(self.on_bottle_detected)
        
        print("‚úÖ All systems initialized successfully!")
        return True
    
    def on_bottle_detected(self):
        """Áì∂Â≠êÊ£ÄÊµãÂõûË∞ÉÂáΩÊï∞"""
        if self.robot_controller and not self.robot_controller.is_moving:
            print("üçº Bottle detected! Executing push trajectory...")
            self.robot_controller.execute_push_trajectory(self.audio_manager)
        else:
            print("‚ö†Ô∏è  Robot is busy, skipping trajectory")
    
    def _manual_push_action(self):
        """ÊâãÂä®Êé®Áì∂Âä®‰Ωú - Áî®‰∫éÊâãÂä®Ê®°Âºè"""
        if self.robot_controller and not self.robot_controller.is_moving:
            print("üéØ Manual push triggered!")
            self.robot_controller.execute_push_trajectory(self.audio_manager)
        else:
            print("‚ö†Ô∏è  Robot is busy, cannot execute manual push")
    
    def run_unified_demo(self, cycle_interval=15):
        """ËøêË°åÁªü‰∏ÄÊºîÁ§∫ - ËøûÁª≠YOLOÊ£ÄÊµã + ÂÆöÊó∂Êú∫Âô®‰∫∫Âä®‰Ωú"""
        if not self.camera_system or not self.robot_controller:
            print("‚ùå Systems not properly initialized")
            return
        
        self.demo_running = True
        print("üé¨ Starting Unified Demo (YOLO + Timed Robot)...")
        print("="*60)
        print("Demo Features:")
        print("‚úÖ Continuous YOLO bottle detection")
        print("‚úÖ Automatic robot push every 15 seconds")
        print("‚úÖ Manual trigger with 'p' key")
        print("‚úÖ Audio alerts before movement")
        print(f"‚úÖ Robot cycle interval: {cycle_interval}s")
        print("="*60)
        
        # ÂêØÂä®ÂÆöÊó∂Êú∫Âô®‰∫∫Âä®‰ΩúÁ∫øÁ®ã
        robot_thread = threading.Thread(
            target=self._timed_robot_worker, 
            args=(cycle_interval,), 
            daemon=True
        )
        robot_thread.start()
        print(f"ü§ñ Started timed robot worker (every {cycle_interval}s)")
        
        try:
            # ÂêØÂä®ÊëÑÂÉèÂ§¥Ê£ÄÊµãÂæ™ÁéØÔºà‰∏ªÁ∫øÁ®ãÔºâ- ÊòæÁ§∫Êú∫Âô®‰∫∫Áä∂ÊÄÅ
            self.camera_system.run_detection_loop(
                show_robot_status=True, 
                robot_controller=self.robot_controller
            )
            
        except KeyboardInterrupt:
            print("‚èπÔ∏è  Demo interrupted by user")
        finally:
            self.demo_running = False
            self.cleanup()
    
    def _timed_robot_worker(self, interval):
        """ÂÆöÊó∂Êú∫Âô®‰∫∫Â∑•‰ΩúÁ∫øÁ®ã"""
        print(f"‚è∞ Timed robot worker started (interval: {interval}s)")
        cycle_count = 0
        
        # Á≠âÂæÖÂàùÂßãÂª∂Ëøü
        initial_delay = 5
        print(f"‚è≥ Initial delay: {initial_delay}s before first robot movement...")
        time.sleep(initial_delay)
        
        while self.demo_running:
            if not self.robot_controller.is_moving:
                cycle_count += 1
                print(f"\nüîî Timed Cycle {cycle_count} - Automatic Push Triggered!")
                
                try:
                    # ÊâßË°åÊú∫Âô®‰∫∫Êé®Áì∂Âä®‰Ωú
                    self.robot_controller.execute_push_trajectory(self.audio_manager)
                    print(f"‚úÖ Timed cycle {cycle_count} completed")
                    
                    # Á≠âÂæÖ‰∏ã‰∏Ä‰∏™Âë®Êúü
                    if self.demo_running:
                        print(f"‚è≥ Waiting {interval}s until next automatic push...")
                        time.sleep(interval)
                        
                except Exception as e:
                    print(f"‚ùå Timed robot cycle {cycle_count} failed: {e}")
                    time.sleep(5)  # ÈîôËØØÊó∂Áü≠ÊöÇÁ≠âÂæÖ
            else:
                print("‚ö†Ô∏è  Robot busy, skipping timed cycle...")
                time.sleep(2)  # Êú∫Âô®‰∫∫ÂøôÁ¢åÊó∂Áü≠ÊöÇÁ≠âÂæÖ
        
        print("üîÑ Timed robot worker stopped")
    
    def cleanup(self):
        """Ê∏ÖÁêÜÊâÄÊúâËµÑÊ∫ê"""
        print("üßπ Cleaning up systems...")
        
        if self.camera_system:
            self.camera_system.stop()
            self.camera_system.cleanup()
        
        if self.robot_controller:
            self.robot_controller.disconnect()
        
        if self.audio_manager:
            self.audio_manager.cleanup()
        
        print("‚úÖ Cleanup completed")

def main():
    """‰∏ªÂáΩÊï∞"""
    print("üé™ Integrated Robot Demo")
    print("="*60)
    print("This demo combines:")
    print("1. üì∑ Camera + YOLO bottle detection")
    print("2. ü§ñ Robot arm trajectory (push/pull)")
    print("3. üîä Audio alerts before movement")
    print("="*60)
    
    # ÈÖçÁΩÆÈÄâÈ°π
    try:
        # ÊëÑÂÉèÂ§¥ÈÄâÊã©
        camera_input = input("Enter camera ID (0/1/2/3/4) or Enter for default (4): ").strip()
        camera_id = int(camera_input) if camera_input.isdigit() else 4
        
        # Êú∫Âô®‰∫∫Á´ØÂè£
        if not ROBOT_AVAILABLE:
            print("‚ùå Robot modules not available! Please install lerobot package.")
            return
        
        robot_port = input("Enter robot port (default /dev/ttyACM1): ").strip()
        if not robot_port:
            robot_port = "/dev/ttyACM1"
        
        # ÊºîÁ§∫Ê®°ÂºèÈÄâÊã©
        print("\nDemo modes:")
        print("1. Camera Only (YOLO detection only)")
        print("2. Manual Mode (camera + manual robot trigger)")
        print("3. Unified Mode (camera + timed robot cycles)")
        mode_choice = input("Choose mode (1/2/3): ").strip()
        
        # ÂàõÂª∫Âπ∂ËøêË°åÊºîÁ§∫
        demo = IntegratedDemo()
        
        if demo.initialize_systems(robot_port, camera_id, simulation_mode=False):
            if mode_choice == "3":
                # Áªü‰∏ÄÊ®°Âºè - ÊëÑÂÉèÂ§¥ÊòæÁ§∫ + ÂÆöÊó∂Êú∫Âô®‰∫∫Âä®‰Ωú
                interval = int(input("Robot cycle interval in seconds (default: 15): ") or "15")
                print(f"üé¨ Starting unified mode with {interval}s robot cycles...")
                demo.run_unified_demo(cycle_interval=interval)
            elif mode_choice == "2":
                # ÊâãÂä®Ê®°Âºè - ÊëÑÂÉèÂ§¥ÊòæÁ§∫ + ÊâãÂä®Ëß¶Âèë
                print("üé¨ Starting manual mode (press 'p' to trigger robot)...")
                demo.camera_system.set_detection_callback(demo._manual_push_action)
                demo.camera_system.run_detection_loop()
            else:
                # ‰ªÖÊëÑÂÉèÂ§¥Ê®°Âºè
                print("üé¨ Starting camera-only mode...")
                demo.camera_system.set_detection_callback(None)  # Á¶ÅÁî®Êú∫Âô®‰∫∫Ëß¶Âèë
                demo.camera_system.run_detection_loop()
        else:
            print("‚ùå Demo initialization failed")
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Demo interrupted")
    except Exception as e:
        print(f"‚ùå Demo failed: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()
