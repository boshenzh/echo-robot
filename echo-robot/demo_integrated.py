#!/usr/bin/env python3
"""
Integrated Demo Script for Robot Arm with YOLO Detection and Audio
é›†æˆæ¼”ç¤ºè„šæœ¬ï¼šæœºå™¨äººæ‰‹è‡‚ + YOLOæ£€æµ‹ + éŸ³é¢‘åé¦ˆ

This script                # Quick calibration check
                calibrate = input("Calibrate robot? (y/n): ").strip().lower()
                if calibrate in ['y', 'yes']:
                    print("ğŸ”§ Calibrating robot...")
                    self.robot.calibrate()
                    print("âœ… Calibration completed!")
                
                # Move to initial safe position
                print("ğŸ  Moving to initial safe position...")
                self.move_to_safe_start_position()
                
            except Exception as e:
                print(f"âŒ Robot connection failed: {e}")
                raise RuntimeError(f"âŒ Failed to connect to robot at {port}. Check connection and port.")
        else:
            print("ğŸ® Running in simulation mode")
    
    def move_to_safe_start_position(self):
        """ç§»åŠ¨åˆ°å®‰å…¨çš„èµ·å§‹ä½ç½®"""
        try:
            # è®¡ç®—å®‰å…¨èµ·å§‹ä½ç½®çš„å…³èŠ‚è§’åº¦
            safe_x, safe_y = 0.0, 0.16
            joint2, joint3 = self.inverse_kinematics(safe_x, safe_y)
            
            print(f"ğŸ”§ Moving to safe start: x={safe_x}, y={safe_y}")
            print(f"   Joint angles: shoulder={joint2:.1f}Â°, elbow={joint3:.1f}Â°")
            
            robot_action = {
                'shoulder_lift.pos': joint2,
                'elbow_flex.pos': joint3
            }
            
            if not self.simulation_mode:
                self.robot.send_action(robot_action)
                time.sleep(2.0)  # ç­‰å¾…åˆ°è¾¾ä½ç½®
            
            self.current_x = safe_x
            self.current_y = safe_y
            print("âœ… Robot moved to safe start position")
            
        except Exception as e:
            print(f"âš ï¸  Failed to move to safe start position: {e}")
            print("   Continuing with current position..."). Camera visualization with YOLO bottle detection (from test_camera_yolo.py)
2. Robot trajectory movement: forward/backward push (from lerobot_yolo.py)
3. Audio feedback before robot arm starts movement

Dependencies:
- pip install pygame (for audio)
æˆ–è€…ä½¿ç”¨ç³»ç»ŸéŸ³é¢‘ï¼š
- sudo apt-get install alsa-utils (for aplay)
"""

import cv2
import time
import math
import numpy as np
import threading
import logging
import traceback
import os
import sys
from ultralytics import YOLO

# Audio imports - try multiple options
try:
    import pygame
    AUDIO_METHOD = "pygame"
    print("ğŸ”Š Using pygame for audio")
except ImportError:
    AUDIO_METHOD = "system"
    print("ğŸ”Š Using system commands for audio")

# Robot imports (only if available)
try:
    from lerobot.robots.so100_follower import SO100Follower, SO100FollowerConfig
    ROBOT_AVAILABLE = True
    print("ğŸ¤– Robot modules available")
except ImportError:
    ROBOT_AVAILABLE = False
    print("âš ï¸  Robot modules not available - simulation mode only")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AudioManager:
    """éŸ³é¢‘ç®¡ç†å™¨"""
    
    def __init__(self):
        self.audio_enabled = True
        if AUDIO_METHOD == "pygame":
            try:
                pygame.mixer.init()
                print("âœ… Pygame audio initialized")
            except Exception as e:
                print(f"âŒ Pygame audio initialization failed: {e}")
                self.audio_enabled = False
    
    def play_alert_sound(self, sound_type="push"):
        """æ’­æ”¾è­¦å‘ŠéŸ³"""
        if not self.audio_enabled:
            return
        
        try:
            if AUDIO_METHOD == "pygame":
                self._play_pygame_sound(sound_type)
            else:
                self._play_system_sound(sound_type)
        except Exception as e:
            print(f"âŒ Audio playback failed: {e}")
    
    def _play_pygame_sound(self, sound_type):
        """ä½¿ç”¨pygameæ’­æ”¾å£°éŸ³"""
        # ç”Ÿæˆç®€å•çš„èœ‚é¸£éŸ³
        frequency = 800 if sound_type == "push" else 600
        duration = 0.5
        sample_rate = 22050
        
        # ç”Ÿæˆæ­£å¼¦æ³¢
        frames = int(duration * sample_rate)
        arr = np.zeros((frames, 2))
        
        for i in range(frames):
            wave = np.sin(2 * np.pi * frequency * i / sample_rate)
            arr[i] = [wave, wave]
        
        # è½¬æ¢ä¸ºpygameæ ¼å¼å¹¶æ’­æ”¾
        sound_array = (arr * 32767).astype(np.int16)
        sound = pygame.sndarray.make_sound(sound_array)
        sound.play()
        time.sleep(duration)
    
    def _play_system_sound(self, sound_type):
        """ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æ’­æ”¾å£°éŸ³"""
        if sound_type == "push":
            # é«˜éŸ³è°ƒè­¦å‘Š
            os.system("speaker-test -t sine -f 800 -l 1 > /dev/null 2>&1 &")
        else:
            # ä½éŸ³è°ƒæç¤º
            os.system("speaker-test -t sine -f 600 -l 1 > /dev/null 2>&1 &")
        time.sleep(0.1)
    
    def cleanup(self):
        """æ¸…ç†éŸ³é¢‘èµ„æº"""
        if AUDIO_METHOD == "pygame":
            try:
                pygame.mixer.quit()
            except:
                pass

class RobotController:
    """æœºå™¨äººæ§åˆ¶å™¨"""
    
    def __init__(self, port="/dev/ttyACM1", simulation_mode=False):
        self.simulation_mode = simulation_mode or not ROBOT_AVAILABLE
        self.robot = None
        self.current_x = 0.0
        self.current_y = 0.06  # åˆå§‹yä½ç½® - åœ¨æœºå™¨äººå·¥ä½œç©ºé—´å†…
        self.is_moving = False
        
        if not ROBOT_AVAILABLE:
            raise RuntimeError("âŒ Robot modules not available! Please install lerobot package.")
        
        if not self.simulation_mode:
            try:
                print(f"ğŸ”Œ Connecting to robot at {port}...")
                robot_config = SO100FollowerConfig(port=port)
                self.robot = SO100Follower(robot_config)
                self.robot.connect()
                print("âœ… Robot connected successfully!")
                
                # Quick calibration check
                calibrate = input("Calibrate robot? (y/n): ").strip().lower()
                if calibrate in ['y', 'yes']:
                    print("ï¿½ Calibrating robot...")
                    self.robot.calibrate()
                    print("âœ… Calibration completed!")
                
            except Exception as e:
                print(f"âŒ Robot connection failed: {e}")
                raise RuntimeError(f"âŒ Failed to connect to robot at {port}. Check connection and port.")
        else:
            print("ğŸ® Running in simulation mode")
    
    def inverse_kinematics(self, x, y, l1=0.1159, l2=0.1350):
        """
        Calculate inverse kinematics for a 2-link robotic arm
        ä»lerobot_yolo.pyå¤åˆ¶çš„é€†è¿åŠ¨å­¦è®¡ç®—
        """
        # Calculate joint2 and joint3 offsets in theta1 and theta2
        theta1_offset = math.atan2(0.028, 0.11257)  # theta1 offset when joint2=0
        theta2_offset = math.atan2(0.0052, 0.1349) + theta1_offset  # theta2 offset when joint3=0
        
        # Calculate distance from origin to target point
        r = math.sqrt(x**2 + y**2)
        r_max = l1 + l2  # Maximum reachable distance
        
        # If target point is beyond maximum workspace, scale it to the boundary
        if r > r_max:
            scale_factor = r_max / r
            x *= scale_factor
            y *= scale_factor
            r = r_max
        
        # If target point is less than minimum workspace (|l1-l2|), scale it
        r_min = abs(l1 - l2)
        if r < r_min and r > 0:
            scale_factor = r_min / r
            x *= scale_factor
            y *= scale_factor
            r = r_min
        
        # Use law of cosines to calculate theta2
        cos_theta2 = -(r**2 - l1**2 - l2**2) / (2 * l1 * l2)
        
        # Calculate theta2 (elbow angle)
        theta2 = math.pi - math.acos(cos_theta2)
        
        # Calculate theta1 (shoulder angle)
        beta = math.atan2(y, x)
        gamma = math.atan2(l2 * math.sin(theta2), l1 + l2 * math.cos(theta2))
        theta1 = beta + gamma
        
        # Convert theta1 and theta2 to joint2 and joint3 angles
        joint2 = theta1 + theta1_offset
        joint3 = theta2 + theta2_offset
        
        # Ensure angles are within URDF limits
        joint2 = max(-0.1, min(3.45, joint2))
        joint3 = max(-0.2, min(math.pi, joint3))
        
        # Convert from radians to degrees
        joint2_deg = math.degrees(joint2)
        joint3_deg = math.degrees(joint3)
        
        joint2_deg = 90 - joint2_deg
        joint3_deg = joint3_deg - 90
        
        return joint2_deg, joint3_deg
    
    def move_to_position(self, target_x, target_y, duration=4.0, num_waypoints=5):
        """ç§»åŠ¨åˆ°æŒ‡å®šä½ç½® - ä½¿ç”¨å¤šä¸ªèˆªç‚¹å®ç°å¹³æ»‘è¿åŠ¨"""
        self.is_moving = True
        print(f"ğŸ¯ Moving to position: x={target_x:.3f}, y={target_y:.3f} (duration: {duration}s)")
        
        # éªŒè¯ç›®æ ‡ä½ç½®æ˜¯å¦åœ¨å·¥ä½œç©ºé—´å†…
        distance_from_origin = math.sqrt(target_x**2 + target_y**2)
        l1, l2 = 0.1159, 0.1350
        max_reach = l1 + l2
        min_reach = abs(l1 - l2)
        
        if distance_from_origin > max_reach:
            print(f"âš ï¸  Target position ({target_x:.3f}, {target_y:.3f}) is beyond max reach {max_reach:.3f}m")
            print(f"   Scaling to workspace boundary...")
            scale = max_reach / distance_from_origin
            target_x *= scale
            target_y *= scale
            print(f"   New target: ({target_x:.3f}, {target_y:.3f})")
        elif distance_from_origin < min_reach and distance_from_origin > 0:
            print(f"âš ï¸  Target position ({target_x:.3f}, {target_y:.3f}) is within min reach {min_reach:.3f}m")
            print(f"   Scaling to minimum workspace...")
            scale = min_reach / distance_from_origin
            target_x *= scale
            target_y *= scale
            print(f"   New target: ({target_x:.3f}, {target_y:.3f})")
        
        start_x, start_y = self.current_x, self.current_y
        
        # ç”Ÿæˆä¸­é—´èˆªç‚¹
        waypoints = []
        for i in range(num_waypoints + 1):
            progress = i / num_waypoints
            # ä½¿ç”¨å¹³æ»‘çš„Sæ›²çº¿æ’å€¼ï¼ˆç¼“è¿›ç¼“å‡ºï¼‰
            smooth_progress = self._smooth_interpolation(progress)
            
            wp_x = start_x + (target_x - start_x) * smooth_progress
            wp_y = start_y + (target_y - start_y) * smooth_progress
            waypoints.append((wp_x, wp_y))
        
        print(f"ğŸ“ Generated {len(waypoints)} waypoints for smooth trajectory")
        
        if self.simulation_mode:
            # æ¨¡æ‹Ÿç§»åŠ¨ - é€šè¿‡æ¯ä¸ªèˆªç‚¹
            waypoint_duration = duration / num_waypoints
            
            for i, (wp_x, wp_y) in enumerate(waypoints[1:], 1):  # è·³è¿‡èµ·å§‹ç‚¹
                print(f"ğŸ¯ Waypoint {i}/{num_waypoints}: x={wp_x:.3f}, y={wp_y:.3f}")
                
                # æ¯ä¸ªèˆªç‚¹å†…éƒ¨çš„ç»†åˆ†æ­¥éª¤
                steps_per_waypoint = int(waypoint_duration * 20)  # 20Hz for smooth simulation
                prev_x, prev_y = self.current_x, self.current_y
                
                for j in range(steps_per_waypoint + 1):
                    step_progress = j / steps_per_waypoint
                    
                    current_x = prev_x + (wp_x - prev_x) * step_progress
                    current_y = prev_y + (wp_y - prev_y) * step_progress
                    
                    self.current_x = current_x
                    self.current_y = current_y
                    
                    if j % 10 == 0:  # æ¯0.5ç§’æ˜¾ç¤ºä¸€æ¬¡ä½ç½®
                        print(f"   ğŸ“ Position: x={current_x:.3f}, y={current_y:.3f}")
                    
                    time.sleep(waypoint_duration / steps_per_waypoint)
        else:
            # çœŸå®æœºå™¨äººç§»åŠ¨ - é€šè¿‡æ¯ä¸ªèˆªç‚¹
            try:
                control_freq = 30  # 30Hzæ§åˆ¶é¢‘ç‡
                waypoint_duration = duration / num_waypoints
                steps_per_waypoint = int(waypoint_duration * control_freq)
                
                for i, (wp_x, wp_y) in enumerate(waypoints[1:], 1):  # è·³è¿‡èµ·å§‹ç‚¹
                    print(f"ğŸ¯ Waypoint {i}/{num_waypoints}: x={wp_x:.3f}, y={wp_y:.3f}")
                    
                    # è®¡ç®—è¯¥èˆªç‚¹çš„å…³èŠ‚è§’åº¦
                    joint2, joint3 = self.inverse_kinematics(wp_x, wp_y)
                    print(f"   ğŸ”§ Joint angles: shoulder={joint2:.1f}Â°, elbow={joint3:.1f}Â°")
                    
                    # ä»å½“å‰ä½ç½®å¹³æ»‘ç§»åŠ¨åˆ°èˆªç‚¹
                    prev_x, prev_y = self.current_x, self.current_y
                    
                    for j in range(steps_per_waypoint):
                        step_progress = j / steps_per_waypoint
                        
                        # å½“å‰æ­¥éª¤çš„ç›®æ ‡ä½ç½®
                        intermediate_x = prev_x + (wp_x - prev_x) * step_progress
                        intermediate_y = prev_y + (wp_y - prev_y) * step_progress
                        
                        # è®¡ç®—ä¸­é—´ä½ç½®çš„å…³èŠ‚è§’åº¦
                        inter_joint2, inter_joint3 = self.inverse_kinematics(intermediate_x, intermediate_y)
                        
                        robot_action = {
                            'shoulder_lift.pos': inter_joint2,
                            'elbow_flex.pos': inter_joint3
                        }
                        
                        self.robot.send_action(robot_action)
                        time.sleep(1.0 / control_freq)
                    
                    # æ›´æ–°å½“å‰ä½ç½®åˆ°èˆªç‚¹ä½ç½®
                    self.current_x = wp_x
                    self.current_y = wp_y
                    
                    if i % 2 == 0:  # æ¯éš”ä¸€ä¸ªèˆªç‚¹æ˜¾ç¤ºä½ç½®
                        print(f"   âœ… Reached waypoint {i}: x={wp_x:.3f}, y={wp_y:.3f}")
                
                # æœ€ç»ˆä½ç½®ç¡®è®¤
                self.current_x = target_x
                self.current_y = target_y
                
            except Exception as e:
                print(f"âŒ Robot movement failed: {e}")
        
        self.is_moving = False
        print("âœ… Smooth movement completed")
    
    def _smooth_interpolation(self, t):
        """å¹³æ»‘æ’å€¼å‡½æ•° - Sæ›²çº¿ï¼ˆç¼“è¿›ç¼“å‡ºï¼‰"""
        # ä½¿ç”¨3æ¬¡è´å¡å°”æ›²çº¿å®ç°å¹³æ»‘è¿‡æ¸¡
        # è¿™æä¾›äº†ç¼“æ…¢å¼€å§‹ã€åŠ é€Ÿã€ç„¶åç¼“æ…¢ç»“æŸçš„æ•ˆæœ
        return t * t * (3.0 - 2.0 * t)
    
    def execute_push_trajectory(self, audio_manager):
        """æ‰§è¡Œæ¨ç“¶åŠ¨ä½œè½¨è¿¹ - æ…¢é€Ÿå¹³æ»‘è¿åŠ¨"""
        print("\n" + "="*60)
        print("ğŸš€ STARTING SMOOTH PUSH TRAJECTORY")
        print("="*60)
        
        # æ’­æ”¾éŸ³é¢‘è­¦å‘Š
        print("ğŸ”Š Playing audio alert...")
        audio_manager.play_alert_sound("push")
        
        # ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆ
        time.sleep(1.0)
        
        # å®šä¹‰è½¨è¿¹ç‚¹
        start_pos = (0.0, 0.16)      # èµ·å§‹ä½ç½® - åœ¨æœºå™¨äººå·¥ä½œç©ºé—´å†…
        push_pos = (0.1, 0.16)       # æ¨è¿›ä½ç½® (10cm forward)
        
        print(f"\nğŸ“‹ Smooth Trajectory Plan:")
        print(f"   ğŸ  Start:  x={start_pos[0]:.3f}m, y={start_pos[1]:.3f}m")
        print(f"   ğŸ¯ Target: x={push_pos[0]:.3f}m, y={push_pos[1]:.3f}m")
        print(f"   â±ï¸  Total time: ~12 seconds")
        print(f"   ğŸ›¤ï¸  Using 5 waypoints per movement")
        
        # Phase 1: å‘å‰æ¨è¿› (æ…¢é€Ÿ)
        print(f"\nâ© PHASE 1: Smooth Forward Push (5s)")
        self.move_to_position(push_pos[0], push_pos[1], duration=5.0, num_waypoints=5)
        
        # è¾ƒé•¿åœç•™æ—¶é—´
        print(f"\nâ¸ï¸  PHASE 2: Hold Position (2s)")
        print("   ğŸ¤š Maintaining contact with bottle...")
        time.sleep(2.0)
        
        # Phase 3: å‘åé€€å› (æ…¢é€Ÿ)
        print(f"\nâª PHASE 3: Smooth Backward Retreat (5s)")
        self.move_to_position(start_pos[0], start_pos[1], duration=5.0, num_waypoints=5)
        
        print(f"\n" + "="*60)
        print("âœ… SMOOTH PUSH TRAJECTORY COMPLETED!")
        print("   Total execution time: ~12 seconds")
        print("="*60)
    
    def disconnect(self):
        """æ–­å¼€æœºå™¨äººè¿æ¥"""
        if self.robot and not self.simulation_mode:
            try:
                self.robot.disconnect()
                print("ğŸ”Œ Robot disconnected")
            except:
                pass

class CameraYOLOSystem:
    """æ‘„åƒå¤´YOLOæ£€æµ‹ç³»ç»Ÿ"""
    
    def __init__(self, camera_id=4, model_path="yolov8n.pt"):
        self.camera_id = camera_id
        self.model = None
        self.cap = None
        self.running = False
        self.detection_callback = None
        
        # åˆå§‹åŒ–YOLOæ¨¡å‹
        try:
            self.model = YOLO(model_path)
            print("âœ… YOLO model loaded successfully")
        except Exception as e:
            print(f"âŒ YOLO model loading failed: {e}")
    
    def auto_detect_camera(self):
        """è‡ªåŠ¨æ£€æµ‹å¯ç”¨æ‘„åƒå¤´"""
        print("ğŸ” Auto-detecting cameras...")
        available_cameras = []
        
        for camera_id in range(5):
            cap = cv2.VideoCapture(camera_id)
            if cap.isOpened():
                ret, _ = cap.read()
                if ret:
                    available_cameras.append(camera_id)
                    print(f"âœ… Camera {camera_id} detected")
                cap.release()
        
        if available_cameras:
            print(f"ğŸ“· Available cameras: {available_cameras}")
            return available_cameras[0]
        else:
            print("âŒ No cameras detected")
            return None
    
    def initialize_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        # è‡ªåŠ¨æ£€æµ‹æˆ–ä½¿ç”¨æŒ‡å®šæ‘„åƒå¤´
        if self.camera_id is None:
            self.camera_id = self.auto_detect_camera()
            if self.camera_id is None:
                return False
        
        try:
            self.cap = cv2.VideoCapture(self.camera_id)
            if not self.cap.isOpened():
                print(f"âŒ Cannot open camera {self.camera_id}")
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            print(f"ğŸ“· Camera {self.camera_id} initialized successfully")
            return True
            
        except Exception as e:
            print(f"âŒ Camera initialization failed: {e}")
            return False
    
    def set_detection_callback(self, callback):
        """è®¾ç½®æ£€æµ‹å›è°ƒå‡½æ•°"""
        self.detection_callback = callback
    
    def run_detection_loop(self, show_robot_status=False, robot_controller=None):
        """è¿è¡Œæ£€æµ‹å¾ªç¯"""
        if not self.model or not self.cap:
            print("âŒ Camera or model not initialized")
            return
        
        self.running = True
        fps_counter = 0
        fps_display = 0
        prev_time = time.time()
        detection_count = 0
        start_time = time.time()
        
        print("ğŸ¯ Starting camera detection loop...")
        print("Controls:")
        print("  'q' or ESC: Quit")
        print("  's': Save current frame")
        print("  'p': Manual push trigger")
        if show_robot_status:
            print("  Robot runs automatically every 15 seconds")
        
        try:
            while self.running:
                ret, frame = self.cap.read()
                if not ret:
                    print("âŒ Failed to capture frame")
                    break
                
                # YOLOæ£€æµ‹
                results = self.model(frame, device='cpu', verbose=False)
                
                # å¤„ç†æ£€æµ‹ç»“æœ
                bottle_detected = False
                for result in results:
                    if result.boxes is not None:
                        for box in result.boxes:
                            x1, y1, x2, y2 = map(int, box.xyxy[0])
                            conf = float(box.conf[0])
                            cls = int(box.cls[0])
                            label = self.model.names[cls]
                            
                            # åªæ˜¾ç¤ºç½®ä¿¡åº¦å¤§äº0.5çš„æ£€æµ‹ç»“æœ
                            if conf > 0.5:
                                detection_count += 1
                                
                                # æ£€æŸ¥æ˜¯å¦ä¸ºç“¶å­
                                if 'bottle' in label.lower():
                                    bottle_detected = True
                                
                                # è®¡ç®—ä¸­å¿ƒç‚¹
                                center_x = (x1 + x2) // 2
                                center_y = (y1 + y2) // 2
                                
                                # ç»˜åˆ¶æ£€æµ‹æ¡†
                                color = (0, 255, 255) if 'bottle' in label.lower() else (0, 255, 0)
                                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                                cv2.circle(frame, (center_x, center_y), 5, color, -1)
                                
                                # ç»˜åˆ¶æ ‡ç­¾
                                label_text = f'{label} {conf:.2f}'
                                cv2.putText(frame, label_text, (x1, y1 - 10),
                                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                
                # è®¡ç®—FPS
                current_time = time.time()
                fps_counter += 1
                if current_time - prev_time >= 1.0:
                    fps_display = fps_counter
                    fps_counter = 0
                    prev_time = current_time
                
                # æ˜¾ç¤ºä¿¡æ¯
                info_y = 30
                cv2.putText(frame, f'FPS: {fps_display}', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                info_y += 30
                cv2.putText(frame, f'Camera: {self.camera_id}', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                info_y += 25
                cv2.putText(frame, f'Detections: {detection_count}', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # æ˜¾ç¤ºè¿è¡Œæ—¶é—´
                info_y += 25
                runtime = int(current_time - start_time)
                cv2.putText(frame, f'Runtime: {runtime}s', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # æ˜¾ç¤ºæœºå™¨äººçŠ¶æ€
                if show_robot_status and robot_controller:
                    info_y += 25
                    robot_status = "MOVING" if robot_controller.is_moving else "READY"
                    status_color = (0, 165, 255) if robot_controller.is_moving else (0, 255, 0)
                    cv2.putText(frame, f'Robot: {robot_status}', (10, info_y),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 2)
                    
                    # æ˜¾ç¤ºä¸‹æ¬¡è‡ªåŠ¨æ¨è¿›å€’è®¡æ—¶ï¼ˆä¼°ç®—ï¼‰
                    if not robot_controller.is_moving:
                        info_y += 25
                        # ç®€å•çš„å€’è®¡æ—¶ä¼°ç®—
                        time_since_start = runtime % 15  # å‡è®¾15ç§’å‘¨æœŸ
                        next_push_in = 15 - time_since_start
                        cv2.putText(frame, f'Next auto push: {next_push_in}s', (10, info_y),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
                
                if bottle_detected:
                    info_y += 25
                    cv2.putText(frame, 'BOTTLE DETECTED!', (10, info_y),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                
                # æ˜¾ç¤ºæ¨¡å¼ä¿¡æ¯
                if show_robot_status:
                    cv2.putText(frame, 'UNIFIED MODE: YOLO + TIMED ROBOT', (10, frame.shape[0] - 60),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 165, 0), 2)
                    cv2.putText(frame, 'Press P for manual push, Q to quit', (10, frame.shape[0] - 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                
                # æ˜¾ç¤ºç”»é¢
                cv2.imshow('Robot Demo - YOLO Detection + Timed Robot', frame)
                
                # æ£€æŸ¥æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:  # ESCé”®é€€å‡º
                    break
                elif key == ord('s'):  # ä¿å­˜å½“å‰å¸§
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    filename = f'demo_frame_{timestamp}.jpg'
                    cv2.imwrite(filename, frame)
                    print(f"ğŸ’¾ Frame saved as {filename}")
                elif key == ord('p'):  # è§¦å‘æ¨ç“¶åŠ¨ä½œ
                    if self.detection_callback:
                        print("ğŸ¯ Manual push trigger activated")
                        threading.Thread(target=self.detection_callback, daemon=True).start()
                
                # è‡ªåŠ¨è§¦å‘ï¼ˆå½“æ£€æµ‹åˆ°ç“¶å­æ—¶ï¼‰
                if bottle_detected and self.detection_callback:
                    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ è‡ªåŠ¨è§¦å‘é€»è¾‘
                    pass
                    
        except KeyboardInterrupt:
            print("â¹ï¸  Detection loop interrupted by user")
        finally:
            self.running = False
    
    def stop(self):
        """åœæ­¢æ£€æµ‹"""
        self.running = False
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()

class IntegratedDemo:
    """é›†æˆæ¼”ç¤ºç³»ç»Ÿ"""
    
    def __init__(self):
        self.audio_manager = AudioManager()
        self.robot_controller = None
        self.camera_system = None
        self.demo_running = False
        
    def initialize_systems(self, robot_port="/dev/ttyACM1", camera_id=4, simulation_mode=False):
        """åˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿ"""
        print("ğŸš€ Initializing Integrated Demo System...")
        print("="*60)
        
        # åˆå§‹åŒ–æœºå™¨äººæ§åˆ¶å™¨
        print("ğŸ¤– Initializing robot controller...")
        self.robot_controller = RobotController(robot_port, simulation_mode)
        
        # åˆå§‹åŒ–æ‘„åƒå¤´ç³»ç»Ÿ
        print("ğŸ“· Initializing camera system...")
        self.camera_system = CameraYOLOSystem(camera_id)
        
        if not self.camera_system.initialize_camera():
            print("âŒ Camera system initialization failed")
            return False
        
        # è®¾ç½®æ£€æµ‹å›è°ƒ
        self.camera_system.set_detection_callback(self.on_bottle_detected)
        
        print("âœ… All systems initialized successfully!")
        return True
    
    def on_bottle_detected(self):
        """ç“¶å­æ£€æµ‹å›è°ƒå‡½æ•°"""
        if self.robot_controller and not self.robot_controller.is_moving:
            print("ğŸ¼ Bottle detected! Executing push trajectory...")
            self.robot_controller.execute_push_trajectory(self.audio_manager)
        else:
            print("âš ï¸  Robot is busy, skipping trajectory")
    
    def _manual_push_action(self):
        """æ‰‹åŠ¨æ¨ç“¶åŠ¨ä½œ - ç”¨äºæ‰‹åŠ¨æ¨¡å¼"""
        if self.robot_controller and not self.robot_controller.is_moving:
            print("ğŸ¯ Manual push triggered!")
            self.robot_controller.execute_push_trajectory(self.audio_manager)
        else:
            print("âš ï¸  Robot is busy, cannot execute manual push")
    
    def run_unified_demo(self, cycle_interval=15):
        """è¿è¡Œç»Ÿä¸€æ¼”ç¤º - è¿ç»­YOLOæ£€æµ‹ + å®šæ—¶æœºå™¨äººåŠ¨ä½œ"""
        if not self.camera_system or not self.robot_controller:
            print("âŒ Systems not properly initialized")
            return
        
        self.demo_running = True
        print("ğŸ¬ Starting Unified Demo (YOLO + Timed Robot)...")
        print("="*60)
        print("Demo Features:")
        print("âœ… Continuous YOLO bottle detection")
        print("âœ… Automatic robot push every 15 seconds")
        print("âœ… Manual trigger with 'p' key")
        print("âœ… Audio alerts before movement")
        print(f"âœ… Robot cycle interval: {cycle_interval}s")
        print("="*60)
        
        # å¯åŠ¨å®šæ—¶æœºå™¨äººåŠ¨ä½œçº¿ç¨‹
        robot_thread = threading.Thread(
            target=self._timed_robot_worker, 
            args=(cycle_interval,), 
            daemon=True
        )
        robot_thread.start()
        print(f"ğŸ¤– Started timed robot worker (every {cycle_interval}s)")
        
        try:
            # å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹å¾ªç¯ï¼ˆä¸»çº¿ç¨‹ï¼‰- æ˜¾ç¤ºæœºå™¨äººçŠ¶æ€
            self.camera_system.run_detection_loop(
                show_robot_status=True, 
                robot_controller=self.robot_controller
            )
            
        except KeyboardInterrupt:
            print("â¹ï¸  Demo interrupted by user")
        finally:
            self.demo_running = False
            self.cleanup()
    
    def _timed_robot_worker(self, interval):
        """å®šæ—¶æœºå™¨äººå·¥ä½œçº¿ç¨‹"""
        print(f"â° Timed robot worker started (interval: {interval}s)")
        cycle_count = 0
        
        # ç­‰å¾…åˆå§‹å»¶è¿Ÿ
        initial_delay = 5
        print(f"â³ Initial delay: {initial_delay}s before first robot movement...")
        time.sleep(initial_delay)
        
        while self.demo_running:
            if not self.robot_controller.is_moving:
                cycle_count += 1
                print(f"\nğŸ”” Timed Cycle {cycle_count} - Automatic Push Triggered!")
                
                try:
                    # æ‰§è¡Œæœºå™¨äººæ¨ç“¶åŠ¨ä½œ
                    self.robot_controller.execute_push_trajectory(self.audio_manager)
                    print(f"âœ… Timed cycle {cycle_count} completed")
                    
                    # ç­‰å¾…ä¸‹ä¸€ä¸ªå‘¨æœŸ
                    if self.demo_running:
                        print(f"â³ Waiting {interval}s until next automatic push...")
                        time.sleep(interval)
                        
                except Exception as e:
                    print(f"âŒ Timed robot cycle {cycle_count} failed: {e}")
                    time.sleep(5)  # é”™è¯¯æ—¶çŸ­æš‚ç­‰å¾…
            else:
                print("âš ï¸  Robot busy, skipping timed cycle...")
                time.sleep(2)  # æœºå™¨äººå¿™ç¢Œæ—¶çŸ­æš‚ç­‰å¾…
        
        print("ğŸ”„ Timed robot worker stopped")
    
    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        print("ğŸ§¹ Cleaning up systems...")
        
        if self.camera_system:
            self.camera_system.stop()
            self.camera_system.cleanup()
        
        if self.robot_controller:
            self.robot_controller.disconnect()
        
        if self.audio_manager:
            self.audio_manager.cleanup()
        
        print("âœ… Cleanup completed")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸª Integrated Robot Demo")
    print("="*60)
    print("This demo combines:")
    print("1. ğŸ“· Camera + YOLO bottle detection")
    print("2. ğŸ¤– Robot arm trajectory (push/pull)")
    print("3. ğŸ”Š Audio alerts before movement")
    print("="*60)
    
    # é…ç½®é€‰é¡¹
    try:
        # æ‘„åƒå¤´é€‰æ‹©
        camera_input = input("Enter camera ID (0/1/2/3/4) or Enter for default (4): ").strip()
        camera_id = int(camera_input) if camera_input.isdigit() else 4
        
        # æœºå™¨äººç«¯å£
        if not ROBOT_AVAILABLE:
            print("âŒ Robot modules not available! Please install lerobot package.")
            return
        
        robot_port = input("Enter robot port (default /dev/ttyACM1): ").strip()
        if not robot_port:
            robot_port = "/dev/ttyACM1"
        
        # æ¼”ç¤ºæ¨¡å¼é€‰æ‹©
        print("\nDemo modes:")
        print("1. Camera Only (YOLO detection only)")
        print("2. Manual Mode (camera + manual robot trigger)")
        print("3. Unified Mode (camera + timed robot cycles)")
        mode_choice = input("Choose mode (1/2/3): ").strip()
        
        # åˆ›å»ºå¹¶è¿è¡Œæ¼”ç¤º
        demo = IntegratedDemo()
        
        if demo.initialize_systems(robot_port, camera_id, simulation_mode=False):
            if mode_choice == "3":
                # ç»Ÿä¸€æ¨¡å¼ - æ‘„åƒå¤´æ˜¾ç¤º + å®šæ—¶æœºå™¨äººåŠ¨ä½œ
                interval = int(input("Robot cycle interval in seconds (default: 15): ") or "15")
                print(f"ğŸ¬ Starting unified mode with {interval}s robot cycles...")
                demo.run_unified_demo(cycle_interval=interval)
            elif mode_choice == "2":
                # æ‰‹åŠ¨æ¨¡å¼ - æ‘„åƒå¤´æ˜¾ç¤º + æ‰‹åŠ¨è§¦å‘
                print("ğŸ¬ Starting manual mode (press 'p' to trigger robot)...")
                demo.camera_system.set_detection_callback(demo._manual_push_action)
                demo.camera_system.run_detection_loop()
            else:
                # ä»…æ‘„åƒå¤´æ¨¡å¼
                print("ğŸ¬ Starting camera-only mode...")
                demo.camera_system.set_detection_callback(None)  # ç¦ç”¨æœºå™¨äººè§¦å‘
                demo.camera_system.run_detection_loop()
        else:
            print("âŒ Demo initialization failed")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Demo interrupted")
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()
