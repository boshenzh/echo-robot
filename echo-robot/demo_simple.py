#!/usr/bin/env python3
"""
Simple Demo Script for Robot Arm with YOLO Detection and Audio
ç®€åŒ–ç‰ˆæ¼”ç¤ºè„šæœ¬ï¼šæœºå™¨äººæ‰‹è‡‚ + YOLOæ£€æµ‹ + éŸ³é¢‘åé¦ˆ

This is a lightweight version that uses system beep for audio.
è¿™æ˜¯ä½¿ç”¨ç³»ç»Ÿèœ‚é¸£å™¨çš„è½»é‡çº§ç‰ˆæœ¬ã€‚

Features:
1. Camera visualization with YOLO bottle detection
2. Robot trajectory: forward/backward push motion  
3. Simple audio beep before robot movement
4. Can run in simulation mode without robot hardware

Requirements:
- OpenCV
- ultralytics (YOLO)
- lerobot (optional, for real robot)
"""

import cv2
import time
import math
import threading
import os
import sys
from ultralytics import YOLO

# Try to import robot modules
try:
    from lerobot.robots.so100_follower import SO100Follower, SO100FollowerConfig
    ROBOT_AVAILABLE = True
    print("ğŸ¤– Robot modules available")
except ImportError:
    ROBOT_AVAILABLE = False
    print("âš ï¸  Robot modules not available - simulation mode only")

def play_beep_sound(duration=0.5, frequency=800):
    """æ’­æ”¾ç®€å•èœ‚é¸£éŸ³"""
    try:
        # Try different methods for audio feedback
        if os.name == 'posix':  # Linux/macOS
            # Method 1: Use speaker-test (most common on Linux)
            os.system(f"timeout {duration} speaker-test -t sine -f {frequency} -l 1 >/dev/null 2>&1 &")
        else:
            # Method 2: Use print bell character as fallback
            print(f"\a")  # Bell character
        
        print(f"ğŸ”Š Audio alert: {frequency}Hz for {duration}s")
    except Exception as e:
        print(f"âš ï¸  Audio alert failed: {e}")
        print("ğŸ”” BEEP! (Robot starting movement)")

class SimpleRobotController:
    """ç®€åŒ–æœºå™¨äººæ§åˆ¶å™¨"""
    
    def __init__(self, port="/dev/ttyACM1", simulation_mode=False):
        self.simulation_mode = simulation_mode or not ROBOT_AVAILABLE
        self.robot = None
        self.current_x = 0.0
        self.current_y = 0.16  # Starting Y position
        self.is_moving = False
        
        if not ROBOT_AVAILABLE:
            raise RuntimeError("âŒ Robot modules not available! Please install lerobot package.")
        
        if not self.simulation_mode:
            try:
                print(f"ğŸ”Œ Connecting to robot at {port}...")
                robot_config = SO100FollowerConfig(port=port)
                self.robot = SO100Follower(robot_config)
                self.robot.connect()
                print("âœ… Robot connected successfully!")
                
                # Quick calibration check
                calibrate = input("Calibrate robot? (y/n): ").strip().lower()
                if calibrate in ['y', 'yes']:
                    print("ğŸ”§ Calibrating robot...")
                    self.robot.calibrate()
                    print("âœ… Calibration completed!")
                
            except Exception as e:
                print(f"âŒ Robot connection failed: {e}")
                raise RuntimeError(f"âŒ Failed to connect to robot at {port}. Check connection and port.")
        else:
            print("ğŸ® Running in simulation mode")
    
    def inverse_kinematics_simple(self, x, y):
        """ç®€åŒ–çš„é€†è¿åŠ¨å­¦è®¡ç®—"""
        # ç®€å•çš„2å…³èŠ‚é€†è¿åŠ¨å­¦
        l1, l2 = 0.1159, 0.1350  # Link lengths
        
        # ç¡®ä¿ç›®æ ‡åœ¨å·¥ä½œç©ºé—´å†…
        r = math.sqrt(x**2 + y**2)
        r_max = l1 + l2
        
        if r > r_max:
            scale = r_max / r
            x *= scale
            y *= scale
            r = r_max
        
        # è®¡ç®—å…³èŠ‚è§’åº¦ (ç®€åŒ–ç‰ˆ)
        cos_theta2 = (r**2 - l1**2 - l2**2) / (2 * l1 * l2)
        cos_theta2 = max(-1, min(1, cos_theta2))  # Clamp to valid range
        
        theta2 = math.acos(cos_theta2)
        theta1 = math.atan2(y, x) - math.atan2(l2 * math.sin(theta2), l1 + l2 * math.cos(theta2))
        
        # è½¬æ¢ä¸ºåº¦æ•°
        joint2_deg = math.degrees(theta1)
        joint3_deg = math.degrees(theta2)
        
        return joint2_deg, joint3_deg
    
    def move_to_position(self, target_x, target_y, duration=4.0, num_waypoints=5):
        """ç§»åŠ¨åˆ°æŒ‡å®šä½ç½® - ä½¿ç”¨å¤šä¸ªèˆªç‚¹å®ç°å¹³æ»‘è¿åŠ¨"""
        self.is_moving = True
        print(f"ğŸ¯ Moving to position: x={target_x:.3f}, y={target_y:.3f} (duration: {duration}s)")
        
        start_x, start_y = self.current_x, self.current_y
        
        # ç”Ÿæˆä¸­é—´èˆªç‚¹
        waypoints = []
        for i in range(num_waypoints + 1):
            progress = i / num_waypoints
            # ä½¿ç”¨å¹³æ»‘çš„Sæ›²çº¿æ’å€¼ï¼ˆç¼“è¿›ç¼“å‡ºï¼‰
            smooth_progress = self._smooth_interpolation(progress)
            
            wp_x = start_x + (target_x - start_x) * smooth_progress
            wp_y = start_y + (target_y - start_y) * smooth_progress
            waypoints.append((wp_x, wp_y))
        
        print(f"ğŸ“ Generated {len(waypoints)} waypoints for smooth trajectory")
        
        if self.simulation_mode:
            # æ¨¡æ‹Ÿç§»åŠ¨ - é€šè¿‡æ¯ä¸ªèˆªç‚¹
            waypoint_duration = duration / num_waypoints
            
            for i, (wp_x, wp_y) in enumerate(waypoints[1:], 1):  # è·³è¿‡èµ·å§‹ç‚¹
                print(f"ğŸ¯ Waypoint {i}/{num_waypoints}: x={wp_x:.3f}, y={wp_y:.3f}")
                
                # æ¯ä¸ªèˆªç‚¹å†…éƒ¨çš„ç»†åˆ†æ­¥éª¤
                steps_per_waypoint = int(waypoint_duration * 20)  # 20Hz for smooth simulation
                prev_x, prev_y = self.current_x, self.current_y
                
                for j in range(steps_per_waypoint + 1):
                    step_progress = j / steps_per_waypoint
                    
                    current_x = prev_x + (wp_x - prev_x) * step_progress
                    current_y = prev_y + (wp_y - prev_y) * step_progress
                    
                    self.current_x = current_x
                    self.current_y = current_y
                    
                    if j % 10 == 0:  # æ¯0.5ç§’æ˜¾ç¤ºä¸€æ¬¡ä½ç½®
                        print(f"   ğŸ“ Position: x={current_x:.3f}, y={current_y:.3f}")
                    
                    time.sleep(waypoint_duration / steps_per_waypoint)
        else:
            # çœŸå®æœºå™¨äººç§»åŠ¨ - é€šè¿‡æ¯ä¸ªèˆªç‚¹
            try:
                control_freq = 30  # 30Hzæ§åˆ¶é¢‘ç‡
                waypoint_duration = duration / num_waypoints
                steps_per_waypoint = int(waypoint_duration * control_freq)
                
                for i, (wp_x, wp_y) in enumerate(waypoints[1:], 1):  # è·³è¿‡èµ·å§‹ç‚¹
                    print(f"ğŸ¯ Waypoint {i}/{num_waypoints}: x={wp_x:.3f}, y={wp_y:.3f}")
                    
                    # è®¡ç®—è¯¥èˆªç‚¹çš„å…³èŠ‚è§’åº¦
                    joint2, joint3 = self.inverse_kinematics_simple(wp_x, wp_y)
                    
                    # ä»å½“å‰ä½ç½®å¹³æ»‘ç§»åŠ¨åˆ°èˆªç‚¹
                    prev_x, prev_y = self.current_x, self.current_y
                    
                    for j in range(steps_per_waypoint):
                        step_progress = j / steps_per_waypoint
                        
                        # å½“å‰æ­¥éª¤çš„ç›®æ ‡ä½ç½®
                        intermediate_x = prev_x + (wp_x - prev_x) * step_progress
                        intermediate_y = prev_y + (wp_y - prev_y) * step_progress
                        
                        # è®¡ç®—ä¸­é—´ä½ç½®çš„å…³èŠ‚è§’åº¦
                        inter_joint2, inter_joint3 = self.inverse_kinematics_simple(intermediate_x, intermediate_y)
                        
                        robot_action = {
                            'shoulder_lift.pos': inter_joint2,
                            'elbow_flex.pos': inter_joint3
                        }
                        
                        self.robot.send_action(robot_action)
                        time.sleep(1.0 / control_freq)
                    
                    # æ›´æ–°å½“å‰ä½ç½®åˆ°èˆªç‚¹ä½ç½®
                    self.current_x = wp_x
                    self.current_y = wp_y
                    
                    if i % 2 == 0:  # æ¯éš”ä¸€ä¸ªèˆªç‚¹æ˜¾ç¤ºä½ç½®
                        print(f"   âœ… Reached waypoint {i}: x={wp_x:.3f}, y={wp_y:.3f}")
                
                # æœ€ç»ˆä½ç½®ç¡®è®¤
                self.current_x = target_x
                self.current_y = target_y
                
            except Exception as e:
                print(f"âŒ Robot movement failed: {e}")
        
        self.is_moving = False
        print("âœ… Smooth movement completed")
    
    def _smooth_interpolation(self, t):
        """å¹³æ»‘æ’å€¼å‡½æ•° - Sæ›²çº¿ï¼ˆç¼“è¿›ç¼“å‡ºï¼‰"""
        # ä½¿ç”¨3æ¬¡è´å¡å°”æ›²çº¿å®ç°å¹³æ»‘è¿‡æ¸¡
        # è¿™æä¾›äº†ç¼“æ…¢å¼€å§‹ã€åŠ é€Ÿã€ç„¶åç¼“æ…¢ç»“æŸçš„æ•ˆæœ
        return t * t * (3.0 - 2.0 * t)
    
    def execute_push_sequence(self):
        """æ‰§è¡Œæ¨ç“¶åºåˆ— - æ…¢é€Ÿå¹³æ»‘è¿åŠ¨"""
        print("\n" + "="*60)
        print("ğŸš€ STARTING SMOOTH PUSH SEQUENCE")
        print("="*60)
        
        # æ’­æ”¾éŸ³é¢‘è­¦å‘Š
        print("ğŸ”Š Playing audio warning...")
        play_beep_sound(duration=0.8, frequency=800)
        time.sleep(1.0)  # ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆ
        
        # å®šä¹‰è½¨è¿¹ç‚¹
        start_pos = (0.0, 0.16)    # èµ·å§‹ä½ç½®
        push_pos = (0.1, 0.16)     # æ¨è¿›ä½ç½® (10cm forward)
        
        print(f"\nğŸ“‹ Smooth Trajectory Plan:")
        print(f"   ğŸ  Start:  x={start_pos[0]:.3f}m, y={start_pos[1]:.3f}m")
        print(f"   ğŸ¯ Target: x={push_pos[0]:.3f}m, y={push_pos[1]:.3f}m")
        print(f"   â±ï¸  Total time: ~12 seconds")
        print(f"   ğŸ›¤ï¸  Using 5 waypoints per movement")
        
        # Phase 1: å‘å‰æ¨è¿›
        print(f"\nâ© PHASE 1: Smooth Forward Push (5s)")
        self.move_to_position(push_pos[0], push_pos[1], duration=5.0, num_waypoints=5)
        
        # çŸ­æš‚åœç•™
        print(f"\nâ¸ï¸  PHASE 2: Hold Position (2s)")
        print("   ğŸ¤š Maintaining contact with bottle...")
        time.sleep(2.0)
        
        # Phase 3: å‘åé€€å›
        print(f"\nâª PHASE 3: Smooth Backward Retreat (5s)")
        self.move_to_position(start_pos[0], start_pos[1], duration=5.0, num_waypoints=5)
        
        print(f"\n" + "="*60)
        print("âœ… SMOOTH PUSH SEQUENCE COMPLETED!")
        print("   Total execution time: ~12 seconds")
        print("="*60)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.robot and not self.simulation_mode:
            try:
                print("ğŸ”Œ Disconnecting robot...")
                self.robot.disconnect()
                print("âœ… Robot disconnected")
            except:
                pass

class SimpleCameraYOLO:
    """ç®€åŒ–æ‘„åƒå¤´YOLOç³»ç»Ÿ"""
    
    def __init__(self, camera_id=4):
        self.camera_id = camera_id
        self.model = None
        self.cap = None
        self.running = False
        self.detection_callback = None
        
        # åŠ è½½YOLOæ¨¡å‹
        try:
            print("ğŸ¤– Loading YOLO model...")
            self.model = YOLO("yolov8n.pt")
            print("âœ… YOLO model loaded successfully")
        except Exception as e:
            print(f"âŒ YOLO model loading failed: {e}")
            raise
    
    def find_camera(self):
        """æŸ¥æ‰¾å¯ç”¨æ‘„åƒå¤´"""
        print("ğŸ” Searching for cameras...")
        
        for i in range(5):
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                ret, _ = cap.read()
                if ret:
                    print(f"âœ… Found working camera: {i}")
                    cap.release()
                    return i
                cap.release()
        
        print("âŒ No working cameras found")
        return None
    
    def initialize_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        if self.camera_id is None:
            self.camera_id = self.find_camera()
            if self.camera_id is None:
                return False
        
        try:
            print(f"ğŸ“· Initializing camera {self.camera_id}...")
            self.cap = cv2.VideoCapture(self.camera_id)
            
            if not self.cap.isOpened():
                print(f"âŒ Cannot open camera {self.camera_id}")
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            # æµ‹è¯•è¯»å–
            ret, _ = self.cap.read()
            if not ret:
                print("âŒ Camera cannot capture frames")
                return False
            
            print("âœ… Camera initialized successfully")
            return True
            
        except Exception as e:
            print(f"âŒ Camera initialization failed: {e}")
            return False
    
    def set_detection_callback(self, callback):
        """è®¾ç½®ç“¶å­æ£€æµ‹å›è°ƒ"""
        self.detection_callback = callback
    
    def run_detection(self):
        """è¿è¡Œæ£€æµ‹å¾ªç¯"""
        if not self.model or not self.cap:
            print("âŒ Camera or model not ready")
            return
        
        self.running = True
        print("\nğŸ¯ Starting camera detection...")
        print("Controls:")
        print("  'q' or ESC: Quit")
        print("  'p': Manual push trigger")
        print("  's': Save current frame")
        print("-" * 40)
        
        fps_count = 0
        fps_display = 0
        last_time = time.time()
        detection_count = 0
        
        try:
            while self.running:
                ret, frame = self.cap.read()
                if not ret:
                    print("âŒ Failed to read frame")
                    break
                
                # YOLOæ£€æµ‹
                results = self.model(frame, device='cpu', verbose=False)
                
                # å¤„ç†æ£€æµ‹ç»“æœ
                bottle_detected = False
                for result in results:
                    if result.boxes is not None:
                        for box in result.boxes:
                            x1, y1, x2, y2 = map(int, box.xyxy[0])
                            conf = float(box.conf[0])
                            cls = int(box.cls[0])
                            label = self.model.names[cls]
                            
                            if conf > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                                detection_count += 1
                                
                                # æ£€æŸ¥æ˜¯å¦ä¸ºç“¶å­ç±»åˆ«
                                if 'bottle' in label.lower():
                                    bottle_detected = True
                                
                                # ç»˜åˆ¶æ£€æµ‹æ¡†
                                color = (0, 255, 255) if bottle_detected else (0, 255, 0)
                                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                                
                                # ç»˜åˆ¶æ ‡ç­¾
                                label_text = f'{label} {conf:.2f}'
                                cv2.putText(frame, label_text, (x1, y1 - 10),
                                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                
                # è®¡ç®—FPS
                fps_count += 1
                current_time = time.time()
                if current_time - last_time >= 1.0:
                    fps_display = fps_count
                    fps_count = 0
                    last_time = current_time
                
                # æ˜¾ç¤ºä¿¡æ¯
                cv2.putText(frame, f'FPS: {fps_display}', (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(frame, f'Detections: {detection_count}', (10, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                if bottle_detected:
                    cv2.putText(frame, 'BOTTLE DETECTED!', (10, 90),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                
                # æ˜¾ç¤ºçª—å£
                cv2.imshow('Simple Robot Demo - YOLO Detection', frame)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:  # ESCé€€å‡º
                    break
                elif key == ord('p'):  # æ‰‹åŠ¨è§¦å‘æ¨è¿›
                    if self.detection_callback:
                        print("ğŸ¯ Manual push trigger activated!")
                        threading.Thread(target=self.detection_callback, daemon=True).start()
                elif key == ord('s'):  # ä¿å­˜å¸§
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    filename = f'demo_frame_{timestamp}.jpg'
                    cv2.imwrite(filename, frame)
                    print(f"ğŸ’¾ Frame saved: {filename}")
                
        except KeyboardInterrupt:
            print("â¹ï¸  Detection interrupted")
        finally:
            self.running = False
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸª Simple Robot Demo")
    print("="*50)
    print("Features:")
    print("âœ… Camera + YOLO bottle detection")
    print("âœ… Robot push/pull trajectory")
    print("âœ… Audio beep before movement")
    print("âœ… Manual trigger with 'p' key")
    print("="*50)
    
    robot_controller = None
    camera_system = None
    
    try:
        # é…ç½®å‚æ•°
        print("\nğŸ“‹ Configuration:")
        
        # æ‘„åƒå¤´é€‰æ‹©
        camera_input = input("Camera ID (0/1/2/3/4) or Enter for default (4): ").strip()
        camera_id = int(camera_input) if camera_input.isdigit() else 4
        
        # æœºå™¨äººè®¾ç½®
        if not ROBOT_AVAILABLE:
            print("âŒ Robot modules not available! Please install lerobot package.")
            return
        
        robot_port = input("Robot port (default /dev/ttyACM1): ").strip()
        if not robot_port:
            robot_port = "/dev/ttyACM1"
        
        print(f"\nğŸ”§ Settings:")
        print(f"   Camera: {camera_id}")
        print(f"   Robot: {robot_port}")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("\nğŸš€ Initializing systems...")
        
        # æœºå™¨äººæ§åˆ¶å™¨
        robot_controller = SimpleRobotController(robot_port, simulation_mode=False)
        
        # æ‘„åƒå¤´ç³»ç»Ÿ
        camera_system = SimpleCameraYOLO(camera_id)
        if not camera_system.initialize_camera():
            print("âŒ Camera initialization failed")
            return
        
        # è®¾ç½®å›è°ƒ
        camera_system.set_detection_callback(robot_controller.execute_push_sequence)
        
        print("âœ… All systems ready!")
        
        # æ¼”ç¤ºæ¨¡å¼é€‰æ‹©
        print("\nğŸ® Demo modes:")
        print("1. Interactive (camera + manual trigger)")
        print("2. Automatic test (no camera)")
        
        mode = input("Choose mode (1/2): ").strip()
        
        if mode == "2":
            # è‡ªåŠ¨æµ‹è¯•æ¨¡å¼
            print("\nğŸ”„ Automatic test mode")
            cycles = int(input("Number of cycles (default 3): ") or "3")
            
            for i in range(cycles):
                print(f"\nğŸ¯ Cycle {i+1}/{cycles}")
                robot_controller.execute_push_sequence()
                if i < cycles - 1:
                    print("â³ Waiting 5 seconds...")
                    time.sleep(5)
        else:
            # äº¤äº’æ¨¡å¼
            print("\nğŸ¯ Starting interactive demo...")
            camera_system.run_detection()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Demo interrupted")
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†
        print("\nğŸ§¹ Cleaning up...")
        if camera_system:
            camera_system.cleanup()
        if robot_controller:
            robot_controller.cleanup()
        print("âœ… Demo ended")

if __name__ == "__main__":
    main()
