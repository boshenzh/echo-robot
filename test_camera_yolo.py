import cv2
import time
import argparse
import os
import sys
from ultralytics import YOLO

# Add utils directory to path for coordinate transformation
sys.path.append(os.path.join(os.path.dirname(__file__), 'utils'))
try:
    from coordinate_transform import CoordinateTransformer
except ImportError:
    print("âš ï¸  Coordinate transformation not available. Run without calibration.")
    CoordinateTransformer = None

def auto_detect_camera():
    """
    Automatically detect available camera IDs
    è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„æ‘„åƒå¤´ID
    """
    print("ğŸ” Auto-detecting cameras...")
    available_cameras = []
    
    # Test camera IDs 0-10
    for camera_id in range(11):
        cap = cv2.VideoCapture(camera_id)
        if cap.isOpened():
            ret, _ = cap.read()
            if ret:
                available_cameras.append(camera_id)
                print(f"âœ… Camera {camera_id} detected")
            cap.release()
        else:
            cap.release()
    
    if not available_cameras:
        print("âŒ No cameras detected")
        return None
    
    print(f"ğŸ“· Available cameras: {available_cameras}")
    return available_cameras[0]  # Return first available camera

def main():
    """
    å®æ—¶æ‘„åƒå¤´YOLOç›®æ ‡æ£€æµ‹ï¼Œé›†æˆæ‘„åƒå¤´æ ‡å®šå’Œåæ ‡è½¬æ¢
    Real-time camera YOLO detection with camera calibration and coordinate transformation
    """
    
    parser = argparse.ArgumentParser(description='Camera YOLO Detection with Calibration')
    parser.add_argument('--camera-id', type=int, default=None, help='Camera ID (auto-detect if not specified)')
    parser.add_argument('--model', type=str, default='yolov8n.pt', help='YOLO model path')
    parser.add_argument('--conf-threshold', type=float, default=0.5, help='Confidence threshold')
    parser.add_argument('--use-calibration', action='store_true', help='Use camera calibration for coordinate transformation')
    parser.add_argument('--show-coordinates', action='store_true', help='Show world coordinates for detected objects')
    
    args = parser.parse_args()
    
    # Auto-detect camera if not specified
    camera_id = args.camera_id
    if camera_id is None:
        camera_id = auto_detect_camera()
        if camera_id is None:
            return
    
    # åŠ è½½YOLOæ¨¡å‹
    print(f"ğŸ¤– Loading YOLO model: {args.model}")
    model = YOLO(args.model)
    print("âœ… YOLO model loaded successfully!")
    
    # Initialize coordinate transformer if available and requested
    transformer = None
    if args.use_calibration and CoordinateTransformer:
        transformer = CoordinateTransformer()
        if transformer.is_calibrated:
            print("âœ… Camera calibration loaded")
        else:
            print("âš ï¸  Camera calibration not found. Run: python camera_calibration.py --calibrate")
            transformer = None
    
    # åˆå§‹åŒ–æ‘„åƒå¤´
    print(f"ğŸ“· Initializing camera {camera_id}...")
    cap = cv2.VideoCapture(camera_id)
    
    # æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æˆåŠŸæ‰“å¼€
    if not cap.isOpened():
        print(f"âŒ Error: Could not open camera {camera_id}")
        return
    
    # è®¾ç½®æ‘„åƒå¤´å‚æ•°
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    # Get actual camera resolution
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"ğŸ“ Camera resolution: {width}x{height}")
    
    print("ğŸ¯ Camera initialized successfully!")
    print("Controls æ§åˆ¶è¯´æ˜:")
    print("  'q' or ESC: Quit é€€å‡º")
    print("  's': Save current frame ä¿å­˜å½“å‰å¸§")
    print("  'c': Toggle coordinate display åˆ‡æ¢åæ ‡æ˜¾ç¤º")
    print("  'r': Reset detection statistics é‡ç½®æ£€æµ‹ç»Ÿè®¡")
    
    # ç”¨äºè®¡ç®—FPS
    prev_time = time.time()
    fps_counter = 0
    fps_display = 0
    
    # Detection statistics
    detection_count = 0
    show_coords = args.show_coordinates
    
    try:
        while True:
            # è¯»å–æ‘„åƒå¤´å¸§
            ret, frame = cap.read()
            if not ret:
                print("âŒ Error: Failed to capture frame")
                break
            
            # YOLOæ¨ç†
            results = model(frame, device='cpu', verbose=False)
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        # è·å–è¾¹ç•Œæ¡†åæ ‡
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        
                        # è·å–ç½®ä¿¡åº¦å’Œç±»åˆ«
                        conf = float(box.conf[0])
                        cls = int(box.cls[0])
                        label = model.names[cls]
                        
                        # åªæ˜¾ç¤ºç½®ä¿¡åº¦å¤§äºé˜ˆå€¼çš„æ£€æµ‹ç»“æœ
                        if conf > args.conf_threshold:
                            detection_count += 1
                            
                            # è®¡ç®—è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹
                            center_x = (x1 + x2) // 2
                            center_y = (y1 + y2) // 2
                            
                            # ç»˜åˆ¶è¾¹ç•Œæ¡†
                            color = (0, 255, 0)  # Green for bottle/object
                            if 'bottle' in label.lower():
                                color = (0, 255, 255)  # Yellow for bottles
                            
                            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                            
                            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
                            cv2.circle(frame, (center_x, center_y), 5, color, -1)
                            
                            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
                            label_text = f'{label} {conf:.2f}'
                            
                            # å¦‚æœæœ‰åæ ‡è½¬æ¢ï¼Œæ·»åŠ ä¸–ç•Œåæ ‡
                            if transformer and show_coords:
                                world_x, world_y, world_z = transformer.pixel_to_world_simple(center_x, center_y)
                                label_text += f'\nWorld: ({world_x:.1f}, {world_y:.1f})mm'
                            
                            # ç»˜åˆ¶æ ‡ç­¾
                            lines = label_text.split('\n')
                            y_offset = y1
                            
                            for i, line in enumerate(lines):
                                label_size = cv2.getTextSize(line, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                                
                                # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                                bg_y1 = y_offset - label_size[1] - 10
                                bg_y2 = y_offset
                                cv2.rectangle(frame, (x1, bg_y1), (x1 + label_size[0], bg_y2), color, -1)
                                
                                # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
                                cv2.putText(frame, line, (x1, y_offset - 5),
                                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
                                
                                y_offset = bg_y1
            
            # è®¡ç®—å¹¶æ˜¾ç¤ºFPS
            current_time = time.time()
            fps_counter += 1
            
            if current_time - prev_time >= 1.0:  # æ¯ç§’æ›´æ–°ä¸€æ¬¡FPSæ˜¾ç¤º
                fps_display = fps_counter
                fps_counter = 0
                prev_time = current_time
            
            # æ˜¾ç¤ºä¿¡æ¯
            info_y = 30
            cv2.putText(frame, f'FPS: {fps_display}', (10, info_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            info_y += 30
            cv2.putText(frame, f'Camera: {camera_id}', (10, info_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            info_y += 25
            cv2.putText(frame, f'Detections: {detection_count}', (10, info_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            if transformer:
                info_y += 25
                calib_status = "Calibrated" if transformer.is_calibrated else "Not Calibrated"
                cv2.putText(frame, f'Camera: {calib_status}', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0) if transformer.is_calibrated else (0, 0, 255), 2)
            
            if show_coords:
                info_y += 25
                cv2.putText(frame, 'Coordinates: ON', (10, info_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow('Camera YOLO Detection with Calibration', frame)
            
            # æ£€æŸ¥æŒ‰é”®
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:  # 'q'é”®æˆ–ESCé”®é€€å‡º
                break
            elif key == ord('s'):  # 's'é”®ä¿å­˜å½“å‰å¸§
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f'yolo_detection_{timestamp}.jpg'
                cv2.imwrite(filename, frame)
                print(f"ğŸ’¾ Image saved as {filename}")
            elif key == ord('c'):  # 'c'é”®åˆ‡æ¢åæ ‡æ˜¾ç¤º
                show_coords = not show_coords
                print(f"ğŸ¯ Coordinate display: {'ON' if show_coords else 'OFF'}")
            elif key == ord('r'):  # 'r'é”®é‡ç½®ç»Ÿè®¡
                detection_count = 0
                print("ğŸ”„ Detection statistics reset")
    
    except KeyboardInterrupt:
        print("â¹ï¸  Program interrupted by user")
    
    finally:
        # é‡Šæ”¾èµ„æº
        cap.release()
        cv2.destroyAllWindows()
        print("ğŸ“· Camera released and windows closed")

if __name__ == "__main__":
    main()
